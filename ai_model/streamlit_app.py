import os
import json
import glob
import joblib
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import streamlit as st
import plotly.graph_objects as go
from datetime import timedelta

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from model import TimeSeriesModel, build_model_from_config

# streamlit run .\streamlit_app.py ë¡œ ì‹¤í–‰ ê°€ëŠ¥

# =========================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ í™œìš© ë° ì¶”ê°€)
# =========================

def load_config(config_path: str) -> dict:
    """ê¸°ì¡´ load_config í•¨ìˆ˜"""
    with open(config_path, 'r', encoding='utf-8') as f:
        cfg = json.load(f)
    for key in ['data', 'model', 'artifacts']:
        if key not in cfg:
            raise KeyError(f"configì— '{key}' ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤: {config_path}")
    return cfg

@st.cache_resource
def load_scaler_or_fit(series_1d: np.ndarray, scaler_path: str | None) -> MinMaxScaler:
    """
    1) scaler_pathê°€ ì¡´ì¬í•˜ë©´ ë¡œë“œ
    2) ì—†ìœ¼ë©´ seriesë¥¼ 0~1ë¡œ fit í•´ì„œ ë°˜í™˜
    """
    if scaler_path and os.path.exists(scaler_path):
        print(f"[scaler] ë¡œë“œ: {scaler_path}")
        return joblib.load(scaler_path)
    print("[scaler] íŒŒì¼ì´ ì—†ì–´ ë°ì´í„° ì „ì²´ë¡œ MinMaxScalerë¥¼ ìƒˆë¡œ fit í•©ë‹ˆë‹¤.")
    scaler = MinMaxScaler()
    scaler.fit(series_1d.reshape(-1, 1))
    return scaler

@st.cache_resource
def load_model(_cfg: dict, device: torch.device):
    """ëª¨ë¸ì„ ë¹Œë“œí•˜ê³  ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (Streamlit ìºì‹± ì ìš©)"""
    model, ckpt_path = build_model_from_config(_cfg, device)
    if not os.path.exists(ckpt_path):
        st.error(f"ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ckpt_path}")
        st.stop()
    
    # ê°€ì§œ ëª¨ë¸ì¼ ê²½ìš° state_dict ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤ (ì‹¤ì œ ì‚¬ìš© ì‹œ ì´ ifë¬¸ ì œê±°)
    if 'LSTM_W30_P5.ckpt' not in ckpt_path:
        ckpt = torch.load(ckpt_path, map_location=device)
        model.load_state_dict(ckpt['model_state_dict'])
    
    model.eval()
    return model

def calculate_directional_accuracy(y_true: pd.Series, y_pred: pd.Series) -> float:
    """ë°©í–¥ì„± ì •í™•ë„ ê³„ì‚°"""
    true_diff = y_true.diff().dropna()
    pred_diff = (y_pred - y_true.shift(1)).dropna() # ì˜ˆì¸¡ê°’ì˜ ë³€í™”ëŠ” 'ì–´ì œ ì‹¤ì œê°’' ëŒ€ë¹„ë¡œ ê³„ì‚°
    
    # ê°™ì€ ì¸ë±ìŠ¤ë§Œ ë¹„êµ
    common_index = true_diff.index.intersection(pred_diff.index)
    if len(common_index) == 0:
        return 0.0
        
    true_diff = true_diff[common_index]
    pred_diff = pred_diff[common_index]

    correct_direction = (np.sign(true_diff) == np.sign(pred_diff)).sum()
    return (correct_direction / len(common_index)) * 100 if len(common_index) > 0 else 0.0


@st.cache_data
def run_rolling_prediction(_model, full_scaled_data: np.ndarray, window_size: int, pred_days: int, start_idx: int, end_idx: int) -> np.ndarray:
    """
    ì„ íƒëœ ê¸°ê°„ì— ëŒ€í•´ Walk-Forward ë°©ì‹ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    (ë§¤ì¼ë§¤ì¼ ê³¼ê±° window_sizeì¼ì˜ ë°ì´í„°ë¡œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê³¼ì •ì„ ë°˜ë³µ)
    """
    predictions = []
    device = next(_model.parameters()).device

    for i in range(start_idx, end_idx):
        if i < window_size:
            # ì˜ˆì¸¡ì— í•„ìš”í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° NaN ì²˜ë¦¬
            pred_for_date = np.full((pred_days,), np.nan)
        else:
            window_data = full_scaled_data[i-window_size:i]
            x_infer = window_data.reshape(1, window_size, 1)
            
            with torch.no_grad():
                x_t = torch.from_numpy(x_infer).to(device)
                pred_scaled = _model(x_t).cpu().numpy()
                pred_for_date = pred_scaled.flatten()

        predictions.append(pred_for_date)
        
    return np.array(predictions)


# =========================
# Streamlit App UI ë° ë©”ì¸ ë¡œì§
# =========================
def main():
    st.set_page_config(page_title="LSTM ì„±ëŠ¥ ë¶„ì„ê¸°", layout="wide")
    st.title("ğŸ“ˆ LSTM ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    # --- ì‚¬ì´ë“œë°” ì„¤ì • ---
    st.sidebar.header("âš™ï¸ ëª¨ë¸ ë° ê¸°ê°„ ì„¤ì •")
    
    # 1. ëª¨ë¸(config) ì„ íƒ
    model_dir = 'models'
    config_files = glob.glob(os.path.join(model_dir, "*.config.json"))
    if not config_files:
        st.error(f"'{model_dir}' í´ë”ì— .config.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    selected_config_path = st.sidebar.selectbox(
        "ë¶„ì„í•  ëª¨ë¸ì˜ Config íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:",
        config_files,
        format_func=lambda x: os.path.basename(x)
    )
    
    # --- ì„¤ì • ë° ë°ì´í„° ë¡œë“œ ---
    cfg = load_config(selected_config_path)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    data_path = cfg['data']['file_path']
    feature = cfg['data'].get('feature_name', 'DATA_VALUE')
    window = int(cfg['data']['window_size'])
    pred_days = int(cfg['data']['prediction_days'])
    
    df_full = pd.read_excel(data_path, index_col=0, parse_dates=True)
    prices = df_full[feature].values.astype(np.float32)
    
    scaler_path = os.path.join(cfg['artifacts']['model_dir'], 'scaler.pkl')
    scaler = load_scaler_or_fit(prices, scaler_path)
    scaled_prices = scaler.transform(prices.reshape(-1, 1)).astype(np.float32)

    model = load_model(cfg, device)

    # 2. ë¶„ì„ ê¸°ê°„ ì„ íƒ
    st.sidebar.subheader("ğŸ—“ï¸ ì„±ëŠ¥ ë¶„ì„ ê¸°ê°„")
    min_date = df_full.index.min().date()
    max_date = df_full.index.max().date()
    
    # ì˜ˆì¸¡ì„ ìœ„í•´ ìµœì†Œ window_sizeì¼ì˜ ë°ì´í„°ê°€ í•„ìš”í•˜ë¯€ë¡œ ì‹œì‘ ê°€ëŠ¥ì¼ ì¡°ì •
    eval_start_date = st.sidebar.date_input("ì‹œì‘ì¼", 
        value=max_date - timedelta(days=90),
        min_value=min_date + timedelta(days=window),
        max_value=max_date
    )
    eval_end_date = st.sidebar.date_input("ì¢…ë£Œì¼", 
        value=max_date,
        min_value=eval_start_date,
        max_value=max_date
    )
    
    # --- ë©”ì¸ ëŒ€ì‹œë³´ë“œ ---
    st.header(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: _{eval_start_date.strftime('%Y-%m-%d')} ~ {eval_end_date.strftime('%Y-%m-%d')}_", divider='rainbow')

    # ì„ íƒëœ ê¸°ê°„ì— ëŒ€í•œ ì¸ë±ìŠ¤ ì°¾ê¸°
    date_index = df_full.index
    start_idx = date_index.searchsorted(pd.to_datetime(eval_start_date))
    end_idx = date_index.searchsorted(pd.to_datetime(eval_end_date))

    # ë¡¤ë§ ì˜ˆì¸¡ ìˆ˜í–‰
    rolling_preds_scaled = run_rolling_prediction(model, scaled_prices, window, pred_days, start_idx, end_idx)
    
    # ê²°ê³¼ ì—­ìŠ¤ì¼€ì¼ë§ ë° DataFrame ìƒì„±
    # Pì¼ ì˜ˆì¸¡ ì¤‘ ì²«ë‚ (+1ì¼) ì˜ˆì¸¡ì¹˜ë§Œ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
    pred_plus_1_day_scaled = rolling_preds_scaled[:, 0]
    pred_plus_1_day = scaler.inverse_transform(pred_plus_1_day_scaled.reshape(-1, 1)).flatten()

    result_df = df_full.iloc[start_idx:end_idx].copy()
    result_df['Predicted'] = pred_plus_1_day
    result_df.dropna(inplace=True) # ì˜ˆì¸¡ì´ ë¶ˆê°€ëŠ¥í–ˆë˜ ì´ˆë°˜ ë°ì´í„° ì œê±°
    
    if result_df.empty:
        st.warning("ì„ íƒëœ ê¸°ê°„ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    y_true = result_df['Actual'] = result_df[feature] # ëª…í™•ì„±ì„ ìœ„í•´ 'Actual' ì»¬ëŸ¼ ì¶”ê°€
    y_pred = result_df['Predicted']
    
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    da = calculate_directional_accuracy(y_true, y_pred)
    
    st.subheader("ğŸ¯ í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ")
    col1, col2, col3 = st.columns(3)
    col1.metric("RMSE", f"{rmse:.2f}", help="ëª¨ë¸ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì‚¬ì´ì˜ í‰ê·  ì˜¤ì°¨ í¬ê¸°ì…ë‹ˆë‹¤.")
    col2.metric("ë°©í–¥ì„± ì •í™•ë„ (DA)", f"{da:.2f} %", help="ì‹¤ì œ ë“±ë½ ë°©í–¥(ìƒìŠ¹/í•˜ë½)ì„ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í–ˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")

    # ì‹œê°í™”
    st.subheader("ğŸ“ˆ ì‹¤ì œê°’ vs. ì˜ˆì¸¡ê°’ ë¹„êµ ì°¨íŠ¸")
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=result_df.index, y=result_df['Actual'], mode='lines', name='ì‹¤ì œê°’', line=dict(color='royalblue')))
    fig.add_trace(go.Scatter(x=result_df.index, y=result_df['Predicted'], mode='lines', name='ì˜ˆì¸¡ê°’ (+1ì¼)', line=dict(color='tomato', dash='dot')))
    fig.update_layout(title='ì„ íƒ ê¸°ê°„ ë‚´ ì‹¤ì œê°’ê³¼ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼', xaxis_title='ë‚ ì§œ', yaxis_title=feature)
    st.plotly_chart(fig, use_container_width=True)

    with st.expander("ğŸ—‚ï¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
        st.dataframe(result_df[['Actual', 'Predicted']])

if __name__ == "__main__":
    main()