import os
import sys
import json
import asyncio
import warnings
import yfinance as yf
import pandas as pd
import FinanceDataReader as fdr
from datetime import datetime, timedelta

from apscheduler.schedulers.blocking import BlockingScheduler
warnings.filterwarnings("ignore", category=FutureWarning)

# --- í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì • ---
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# --- ì„œë¹„ìŠ¤ ë° ë¡œì§ ì„í¬íŠ¸ ---
from predict_rate_model import Predictor
from app.services.exchange_rate_crawler import get_detailed_exchange_rates, ExchangeRateDetail

# --- ì„¤ì • ---
MODEL_DIRECTORY = "models/seq_120-pred_1-hidden_128-layers_2-batch_16-lr_0.001-scaler_standard-tag_final_1day"
PREDICTION_CACHE_FILE = "prediction_cache.json"

# --- ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë”© ---
if not os.path.exists(MODEL_DIRECTORY):
    raise FileNotFoundError(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{MODEL_DIRECTORY}'")
predictor = Predictor(model_dir=MODEL_DIRECTORY)
print("âœ… Predictorê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

async def run_and_cache_prediction_async():
    """AI ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ê·¸ë˜í”„ìš© ë°ì´í„°ë¥¼ ìºì‹±í•©ë‹ˆë‹¤."""
    print(f"[{datetime.now()}] ğŸ¤– AI ì˜ˆì¸¡ ë° ìºì‹± ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    try:
        # --- 1. ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ---
        seq_len = predictor.config['sequence_length']
        today = datetime.now()
        start_date_fetch = today - timedelta(days=seq_len * 2) # ë„‰ë„‰í•˜ê²Œ ì¡°íšŒ

        # 1.1. yfinance ë° ECOS ë°ì´í„° ì¡°íšŒ
        df_inv_raw = yf.download("KRW=X", start=start_date_fetch, end=today)
        df_inv = df_inv_raw[['Close']]
        df_inv.columns = ['Inv_Close']

        df_ecos = fdr.DataReader('ECOS-KEYSTAT:K152', start_date_fetch, today)
        df_ecos.rename(columns={df_ecos.columns[0]: 'ECOS_Close'}, inplace=True)

        # 1.2. ì‹¤ì‹œê°„ í¬ë¡¤ëŸ¬ë¡œ 'ì˜¤ëŠ˜'ì˜ í˜„ì¬ í™˜ìœ¨ ì¡°íšŒ
        realtime_rates = await get_detailed_exchange_rates()
        today_rate_detail = next((r for r in realtime_rates if "USDKRW" in r.currency), None)
        if not today_rate_detail:
            raise ValueError("ì‹¤ì‹œê°„ USDKRW í™˜ìœ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        today_current_rate = today_rate_detail.rate
        print(f"âœ… ì‹¤ì‹œê°„ í¬ë¡¤ë§ ì™„ë£Œ: í˜„ì¬ í™˜ìœ¨ {today_current_rate:.2f}")

        # --- 2. AI ì˜ˆì¸¡ ì‹¤í–‰ (ê°€ì¥ ìµœì‹  ë°ì´í„° ì‚¬ìš©) ---
        df_merged = pd.merge(df_inv, df_ecos, left_index=True, right_index=True, how='outer')
        df_merged.ffill(inplace=True)
        df_merged['diff'] = df_merged['Inv_Close'] - df_merged['ECOS_Close']
        df_merged.dropna(inplace=True)
        
        input_df_for_ai = df_merged.tail(seq_len)
        if len(input_df_for_ai) < seq_len:
            raise ValueError(f"AI ì˜ˆì¸¡ì— í•„ìš”í•œ ë°ì´í„° ê¸¸ì´({seq_len})ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

        predicted_prices = predictor.predict(input_df_for_ai)
        predicted_rate = round(float(predicted_prices[0]), 2)
        print(f"ğŸ“ˆ AI ì˜ˆì¸¡ ì™„ë£Œ: ì˜ˆì¸¡ í™˜ìœ¨ {predicted_rate:.2f}")

        # --- 3. ê·¸ë˜í”„ìš© ë°ì´í„° ìƒì„± ---
        graph_data_points = []

        # 3.1. ê³¼ê±° ë°ì´í„° (ECOS ê¸°ì¤€, ìµœê·¼ 30ì¼)
        df_historical_30d = df_ecos.tail(30)
        for date, row in df_historical_30d.iterrows():
            graph_data_points.append({
                "date": date.strftime('%Y-%m-%d'),
                "rate": round(row['ECOS_Close'], 2),
                "is_prediction": False
            })

        # 3.2. 'ì˜¤ëŠ˜' ë°ì´í„° (í¬ë¡¤ë§ ê¸°ì¤€)
        today_str = today.strftime('%Y-%m-%d')
        today_point = {
            "date": today_str,
            "rate": round(today_current_rate, 2),
            "is_prediction": False
        }
        graph_data_points.append(today_point)

        # 3.3. ê·¸ë˜í”„ ì—°ê²°ìš© 'ë¸Œë¦¿ì§€' ë°ì´í„°
        bridge_point = today_point.copy()
        bridge_point['is_prediction'] = True
        graph_data_points.append(bridge_point)

        # 3.4. AI ì˜ˆì¸¡ ë°ì´í„° (ì£¼ë§ ì²˜ë¦¬ í¬í•¨)
        weekday = today.weekday() # ì›”ìš”ì¼=0, í† ìš”ì¼=5, ì¼ìš”ì¼=6
        if weekday == 5: # í† ìš”ì¼
            pred_date = today + timedelta(days=2)
        elif weekday == 6: # ì¼ìš”ì¼
            pred_date = today + timedelta(days=1)
        else: # í‰ì¼
            pred_date = today + timedelta(days=1)
        
        prediction_point = {
            "date": pred_date.strftime('%Y-%m-%d'),
            "rate": predicted_rate,
            "is_prediction": True
        }
        graph_data_points.append(prediction_point)
        print(f"ğŸ—“ï¸ ì˜ˆì¸¡ ë‚ ì§œ: {pred_date.strftime('%Y-%m-%d')} (ì˜¤ëŠ˜ì€ {today.strftime('%A')})")

        # --- 4. ìµœì¢… ìºì‹œ íŒŒì¼ ì €ì¥ ---
        cache_data = {
            "updated_at": datetime.now().isoformat(),
            "predictions": graph_data_points
        }
        with open(PREDICTION_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ! '{PREDICTION_CACHE_FILE}' íŒŒì¼ì— ê·¸ë˜í”„ìš© ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì‘ì—… ì‹¤íŒ¨: {e}")

def run_prediction_job():
    """ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë™ê¸° ë˜í¼ í•¨ìˆ˜"""
    asyncio.run(run_and_cache_prediction_async())

# --- ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ---
sched = BlockingScheduler(timezone='Asia/Seoul')
@sched.scheduled_job('interval', minutes=10)
def scheduled_job():
    run_prediction_job()

if __name__ == "__main__":
    print("ğŸš€ AI ì˜ˆì¸¡ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("ì´ˆê¸° ì˜ˆì¸¡ì„ ë¨¼ì € 1íšŒ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    run_prediction_job()

    print("\nğŸ—“ï¸ 10ë¶„ ê°„ê²©ìœ¼ë¡œ ë‹¤ìŒ í¬ë¡¤ë§ ì‘ì—…ì´ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    try:
        sched.start()
    except (KeyboardInterrupt, SystemExit):
        print("ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
